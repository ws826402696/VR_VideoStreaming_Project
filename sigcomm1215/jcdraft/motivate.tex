%!TEX root = main.tex

\section{Motivation}

We start with the background on \vr video streaming and the existing approaches.
We then outline the new \vr video-specific opportunities driven by a better understanding of how viewers perceive \vr video quality, and show the potential gains in user-perceived \vr video quality under limited available bandwidth. 
The section ends with a highlight on the key challenges to realize these potential gains.


\subsection{Background}

\mypara{\vr video streaming}
\vr videos have come to age.
By 2022, there will be over 55 million active VR headsets in the US, which is as many as paying Netflix members in the US in 2018~\cite{https://qz.com/1298512/vr-could-be-as-big-in-the-us-as-netflix-in-five-years-study-shows/}.
Almost all major content providers (YouTube~\cite{??}, Facebook~\cite{??}, Netflix~\cite{??}, Vimeo~\cite{??}, Amazon Prime~\cite{??}, Hulu~\cite{??}, iQIYI~\cite{??}, YouKu~\cite{??}) launched streaming services for \vr videos across many VR platforms~\cite{oculus,samsung,daydreams,etc}, believing that \vr videos are the future of story telling. 
Like non-\vr videos, 
A typical \vr video delivery pipeline is as following. 
A regular video is first encoded using a \vr encoder, and then just as regular videos, the \vr video will be chunked into segments, sent to a content delivery network (CDN) for Internet-scale distribution, and streamed from the CDN edge HTTP servers to \vr headset over the HTTP(S) protocol~\cite{hls,https://www.wowza.com/solutions/streaming-types/virtual-reality-and-360-degree-streaming}.


\mypara{Existing solutions}
A key difference between \vr video and traditional video streaming lies in the fact that the \vr viewers' attention is {\em unevenly} distributed over a large panoramic space and has a greater concentration closer to the viewport center, whereas the non-\vr videos are displayed on a much smaller screen (PC monitor or smartphone screen).
Thus, other than adapting the video quality level periodically, \vr streaming solutions often exploit the additional {\em spatial knobs}---each video frame can be spatially partitioned into tiles each can be streamed and rendered at different quality levels (\eg quantization parameters) in order to improve the quality near the center of user's viewport at the cost of the quality of the rest of the space which the user is unlikely to notice. 
Essentially, these {\em viewport-driven} protocols (\eg~\cite{??,??,??}) assumes that the user-perceived quality of a spatial region is a function of the encoded quality and the region's distance to the viewport center.
The gain of these protocols, however, is limited by the fact that the videos have to be encoded with very short chunks so that the quality level can be adjusted whenever the viewport moves substantially. 
Recently, there is an increasing interest to address this limitation~\cite{??,??,??}.


\mypara{Bounded sensitivity to quality differences}
The uneven distribution of \vr user's sensitivities can be explained by the attention theory~\cite{??,??}, which has been successfully applied to specialized video encoder and human-computer interface. 
The key concept is the just-noticeable difference (JND)---a user tends to notice the difference between two images/videos, only after the difference is greater than a threshold of JND, which depends heavily on the image/video content (as well as the context of the viewer).
\jc{add a few examples of JND, like content luminance, texture complexity}

The viewport-driven streaming protocols can be seen as one design point of using JND which only depends on the distance between a region and the viewport center. 
We have seen a few efforts to introduce the existing JND-based attention models in video streaming~\cite{??,??}, although so far their real application so far has been quite limited.

\subsection{\vr video-specific opportunities}

We first extend the JND model with several \vr video-specific factors that have not been considered in traditional video streaming.

\begin{itemize}

\item \emph{Viewpoint moving speed can influence perceived quality.} One of the most highlighted feature of VR video is that users can freely move their viewpoints. According to our data analysis, more than x\% time, user's viewpoint is moving faster than y deg/s. When user moves his / her viewpoint, perceived quality is significantly improved, since user is unable to detect the distortion. []

\item \emph{Depth of Field (DoF) can influence perceived quality.} In VR display, different objects have different DoF and it is simulated by binocular parallax. Objects with small DoF (which are near to user) have greater parallax, and greater parallax leads to difficulty of binocular fusion, thus human's ability of detecting distortion is weaker.

\item \emph{User's light / dark adaptation can influence perceived quality.} When user wears a HMD in VR display, environmental brightness perceived by eyes is totally depended on luminance of video content itself. So when the scene changes dramatically from dark to light or from light to dark, user's ability of detecting distortion will be weaker for a period of time.

\end{itemize}
%\jc{
%\begin{itemize}
%\item p1: we first extend the jnd model with several \vr specific factors, 1, 2, 3
%\item p2: with the new jnd model (explained latter), the potential improvement is tremendous!
%\end{itemize}
%}


\subsection{Potential improvement}


\subsection{Key challenges}





