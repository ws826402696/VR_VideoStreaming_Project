\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{distance}
\citation{PSPNR}
\citation{luminance1}
\citation{PSPNR}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{contrast_masking}
\citation{letter}
\citation{brain}
\citation{viewpoint-driven1}
\citation{viewpoint-driven2}
\citation{viewpoint-driven3}
\citation{viewpoint-driven4}
\citation{viewpoint-driven5}
\citation{viewpoint-driven6}
\citation{Flare}
\citation{viewpoint-driven1}
\citation{VPprediction}
\citation{Flare}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Current VR streaming solutions}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Monolithic streaming}{2}{subsubsection.2.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Viewpoint-driven streaming}{2}{subsubsection.2.1.2}}
\citation{speed}
\citation{DoF1}
\citation{DoF2}
\citation{adaptation1}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}What influences user-perceived quality}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Challenges}{3}{subsection.2.3}}
\citation{PSPNR}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces PSPNR-bandwidth tradeoff in video encoding with different granularity of rate allocation.\relax }}{4}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{optimalencoding}{{1}{4}{PSPNR-bandwidth tradeoff in video encoding with different granularity of rate allocation.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The ratio of video size after tiling and original video size in each tiling granularity and each bitrate level. We notice that fine-grained tiling introduces serious bitrate efficiency problem, especially in low bandwidth situations in which the overall bitrate of each tile is low.\relax }}{4}{figure.caption.4}}
\newlabel{bitrateefficiency}{{2}{4}{The ratio of video size after tiling and original video size in each tiling granularity and each bitrate level. We notice that fine-grained tiling introduces serious bitrate efficiency problem, especially in low bandwidth situations in which the overall bitrate of each tile is low.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Potential improvement}{4}{subsection.2.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces PSPNR-bandwidth tradeoff of (1) Viewpoint-driven VR streaming. (2) Perceived quality driven VR streaming. (3) Perceived quality driven VR streaming. (with 3 VR factors)\relax }}{4}{figure.caption.5}}
\newlabel{potential1}{{3}{4}{PSPNR-bandwidth tradeoff of (1) Viewpoint-driven VR streaming. (2) Perceived quality driven VR streaming. (3) Perceived quality driven VR streaming. (with 3 VR factors)\relax }{figure.caption.5}{}}
\citation{PSPNR}
\citation{JND}
\@writefile{toc}{\contentsline {section}{\numberline {3}Key insights and ideas}{5}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Insights}{5}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Key ideas to solve the challenges}{5}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Perceived quality measurement}{5}{section.4}}
\citation{PSPNR}
\citation{JND}
\citation{distance}
\citation{distance}
\newlabel{fig_insight_tilinga}{{\caption@xref {fig_insight_tilinga}{ on input line 27}}{6}{Insights}{figure.caption.6}{}}
\newlabel{fig_insight_tilingb}{{\caption@xref {fig_insight_tilingb}{ on input line 32}}{6}{Insights}{figure.caption.6}{}}
\newlabel{fig_insight_tilingc}{{\caption@xref {fig_insight_tilingc}{ on input line 37}}{6}{Insights}{figure.caption.6}{}}
\newlabel{fig_insight_tilingd}{{\caption@xref {fig_insight_tilingd}{ on input line 42}}{6}{Insights}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An example of traditional grid-like tiling and object-based tiling.\relax }}{6}{figure.caption.6}}
\newlabel{fig_insight_tiling}{{4}{6}{An example of traditional grid-like tiling and object-based tiling.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Perceived quality measuring by Just-Noticeable Distortion (JND) model}{6}{subsection.4.1}}
\newlabel{f1}{{1}{6}{Perceived quality measuring by Just-Noticeable Distortion (JND) model}{equation.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Building Just-Noticeable-Distortion Model for VR display}{6}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces JND due to content luminance.\relax }}{6}{figure.caption.7}}
\newlabel{JNDluminance}{{5}{6}{JND due to content luminance.\relax }{figure.caption.7}{}}
\citation{distance}
\citation{PSPNR}
\citation{speed}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces JND due to content luminance \& viewpoint-object distance.\relax }}{7}{figure.caption.8}}
\newlabel{JNDlum-dist}{{6}{7}{JND due to content luminance \& viewpoint-object distance.\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces HMD Parameters\relax }}{7}{table.caption.9}}
\newlabel{table1}{{1}{7}{HMD Parameters\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results}{7}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}JND v.s. luminance \& viewpoint moving speed}{7}{subsubsection.4.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces CDF gram of viewpoint moving speed.\relax }}{8}{figure.caption.10}}
\newlabel{CDFspeed}{{7}{8}{CDF gram of viewpoint moving speed.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces JND due to content luminance and viewpoint moving speed.\relax }}{8}{figure.caption.11}}
\newlabel{JNDspeed-lum-track}{{8}{8}{JND due to content luminance and viewpoint moving speed.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces $f_{track}(v)$, the JND coefficient of viewpoint moving speed.\relax }}{8}{figure.caption.12}}
\newlabel{JNDspeed-track}{{9}{8}{$f_{track}(v)$, the JND coefficient of viewpoint moving speed.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces $f_{notrack}(v)$, the JND coefficient of viewpoint moving speed.\relax }}{8}{figure.caption.13}}
\newlabel{JNDspeed-notrack}{{10}{8}{$f_{notrack}(v)$, the JND coefficient of viewpoint moving speed.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces An example of parallax effect.\relax }}{8}{figure.caption.14}}
\newlabel{v-aconflict}{{11}{8}{An example of parallax effect.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}JND v.s. luminance \& depth of field}{8}{subsubsection.4.3.2}}
\citation{darkadaptation}
\citation{darkadaptation2}
\citation{PSPNR}
\citation{luminance1}
\citation{PSPNR}
\citation{distance}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces JND due to content luminance and Depth-of-Field.\relax }}{9}{figure.caption.15}}
\newlabel{JNDdof-lum}{{12}{9}{JND due to content luminance and Depth-of-Field.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces $f_{DoF}(D)$, the JND coefficient of Depth-of-Field.\relax }}{9}{figure.caption.16}}
\newlabel{JNDdof}{{13}{9}{$f_{DoF}(D)$, the JND coefficient of Depth-of-Field.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}JND v.s. luminance \& light / dark adaptation}{9}{subsubsection.4.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces JND due to content luminance and Depth-of-Field.\relax }}{9}{figure.caption.17}}
\newlabel{JNDadapt-lum}{{14}{9}{JND due to content luminance and Depth-of-Field.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces $f_{adapt}(\Delta e)$, the JND coefficient of light / dark adaptation.\relax }}{9}{figure.caption.18}}
\newlabel{JNDadapt}{{15}{9}{$f_{adapt}(\Delta e)$, the JND coefficient of light / dark adaptation.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Put it together}{9}{subsubsection.4.3.4}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces symbol and definition used for JND computation\relax }}{10}{table.caption.19}}
\newlabel{table2}{{2}{10}{symbol and definition used for JND computation\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Object-based tiling scheme}{10}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Object Detection based on Quality-Bitrate Efficiency}{10}{subsection.5.1}}
\newlabel{QBE}{{9}{10}{Object Detection based on Quality-Bitrate Efficiency}{equation.5.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Tiling video by objects}{10}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The PSPNR-bandwidth tradeoff of proposed Object-based Tiling scheme and traditional grid-like tiling scheme (3*6, 6*12 and 12*24).\relax }}{11}{figure.caption.20}}
\newlabel{tiling}{{16}{11}{The PSPNR-bandwidth tradeoff of proposed Object-based Tiling scheme and traditional grid-like tiling scheme (3*6, 6*12 and 12*24).\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Comparison of object-based tiling and grid-like tiling}{11}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Client-side PSPNR computation and optimization}{11}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Client-side PSPNR computation}{11}{subsection.6.1}}
\newlabel{CJND}{{13}{11}{Client-side PSPNR computation}{equation.6.13}{}}
\newlabel{BJND}{{14}{11}{Client-side PSPNR computation}{equation.6.14}{}}
\newlabel{f1}{{15}{11}{Client-side PSPNR computation}{equation.6.15}{}}
\citation{BOLA}
\citation{MPC}
\citation{BOLA}
\citation{github}
\newlabel{apprxPMSE}{{16}{12}{Client-side PSPNR computation}{equation.6.16}{}}
\newlabel{apprx}{{17}{12}{Client-side PSPNR computation}{equation.6.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}PSPNR optimization}{12}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Level 1: Allocating bitrate of each temporal segment}{12}{subsubsection.6.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Level 2: Allocating bitrate of each spatial tiles}{12}{subsubsection.6.2.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces  PSPNR driven Rate Allocation Algorithm.\relax }}{13}{algorithm.1}}
\newlabel{alg:Framwork}{{1}{13}{PSPNR driven Rate Allocation Algorithm.\relax }{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Workflow of PQVRS.\relax }}{13}{figure.caption.21}}
\newlabel{implementation}{{17}{13}{Workflow of PQVRS.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Implementation}{13}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Server-Side}{13}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Client-Side}{13}{subsection.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Performance Evaluation}{13}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Evaluation Setup}{13}{subsection.8.1}}
\citation{Flare}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Network topology.\relax }}{14}{figure.caption.22}}
\newlabel{network}{{18}{14}{Network topology.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Performance comparison under fixed bandwidth}{14}{subsection.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Performance comparison under real-world bandwidth}{14}{subsection.8.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces PSPNR-bandwidth tradeoff of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }}{14}{figure.caption.23}}
\newlabel{practical_imp}{{19}{14}{PSPNR-bandwidth tradeoff of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces PSPNR of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }}{14}{figure.caption.24}}
\newlabel{practical_imp}{{20}{14}{PSPNR of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Real-world user rating}{14}{subsection.8.4}}
\citation{distance}
\citation{PSPNR}
\citation{brain}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Stalling tradeoff of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }}{15}{figure.caption.25}}
\newlabel{practical_imp}{{21}{15}{Stalling tradeoff of 4 methods: Viewpoint-driven, PQVRS-, PQVRS, theoretical performance.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces User rating rules.\relax }}{15}{figure.caption.26}}
\newlabel{rating_rules}{{22}{15}{User rating rules.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces User rating results.\relax }}{15}{figure.caption.27}}
\newlabel{rating_res}{{23}{15}{User rating results.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Analysis of PQVRS improvement}{15}{subsection.8.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces User rating results for different types of videos.\relax }}{15}{figure.caption.28}}
\newlabel{rating_res}{{24}{15}{User rating results for different types of videos.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces User rating results for videos with different original bitrate.\relax }}{15}{figure.caption.29}}
\newlabel{rating_res}{{25}{15}{User rating results for videos with different original bitrate.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Related Works}{15}{section.9}}
\citation{viewpoint-driven1}
\citation{viewpoint-driven2}
\citation{viewpoint-driven3}
\citation{viewpoint-driven4}
\citation{viewpoint-driven5}
\citation{viewpoint-driven6}
\citation{Flare}
\bibstyle{ACM-Reference-Format}
\bibdata{reference}
\bibcite{github}{{1}{[n. d.]}{{git}}{{??}}}
\bibcite{letter}{{2}{1974}{{Anstis}}{{Anstis}}}
\bibcite{viewpoint-driven1}{{3}{2017}{{Bao et~al\unhbox \voidb@x \hbox {.}}}{{Bao, Wu, Zhang, Ramli, and Liu}}}
\bibcite{DoF1}{{4}{2015}{{Carnegie and Rhee}}{{Carnegie and Rhee}}}
\bibcite{distance}{{5}{2009}{{Chen and Guillemot}}{{Chen and Guillemot}}}
\bibcite{JND}{{6}{1996}{{Chou and Chen}}{{Chou and Chen}}}
\bibcite{PSPNR}{{7}{1995}{{Chou and Li}}{{Chou and Li}}}
\bibcite{viewpoint-driven2}{{8}{2016}{{Gaddam et~al\unhbox \voidb@x \hbox {.}}}{{Gaddam, Riegler, Eg, Halvorsen, and Griwodz}}}
\bibcite{viewpoint-driven3}{{9}{2017}{{Graf et~al\unhbox \voidb@x \hbox {.}}}{{Graf, Timmerer, and Mueller}}}
\bibcite{DoF2}{{10}{2008}{{Hoffman et~al\unhbox \voidb@x \hbox {.}}}{{Hoffman, Girshick, Akeley, and Banks}}}
\bibcite{viewpoint-driven4}{{11}{2016}{{Hosseini and Swaminathan}}{{Hosseini and Swaminathan}}}
\bibcite{contrast_masking}{{12}{1980}{{Legge and Foley}}{{Legge and Foley}}}
\bibcite{darkadaptation}{{13}{1974a}{{Normann and Werblin}}{{Normann and Werblin}}}
\bibcite{adaptation1}{{14}{1974b}{{Normann and Werblin}}{{Normann and Werblin}}}
\bibcite{viewpoint-driven5}{{15}{2017}{{Petrangeli et~al\unhbox \voidb@x \hbox {.}}}{{Petrangeli, Swaminathan, Hosseini, and De~Turck}}}
\bibcite{darkadaptation2}{{16}{1975}{{Pugh}}{{Pugh}}}
\bibcite{Flare}{{17}{2018}{{Qian et~al\unhbox \voidb@x \hbox {.}}}{{Qian, Han, Xiao, and Gopalakrishnan}}}
\bibcite{VPprediction}{{18}{2016}{{Qian et~al\unhbox \voidb@x \hbox {.}}}{{Qian, Ji, Han, and Gopalakrishnan}}}
\bibcite{luminance1}{{19}{1989}{{Safranek and Johnston}}{{Safranek and Johnston}}}
\bibcite{BOLA}{{20}{2016}{{Spiteri et~al\unhbox \voidb@x \hbox {.}}}{{Spiteri, Urgaonkar, and Sitaraman}}}
\bibcite{speed}{{21}{1995}{{Westerink and Teunissen}}{{Westerink and Teunissen}}}
\bibcite{MPC}{{22}{2015}{{Yin et~al\unhbox \voidb@x \hbox {.}}}{{Yin, Jindal, Sekar, and Sinopoli}}}
\bibcite{viewpoint-driven6}{{23}{2016}{{Zare et~al\unhbox \voidb@x \hbox {.}}}{{Zare, Aminlou, Hannuksela, and Gabbouj}}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Conclusion}{16}{section.10}}
\@writefile{toc}{\contentsline {section}{References}{16}{section*.31}}
\bibcite{brain}{{24}{2011}{{Zhao et~al\unhbox \voidb@x \hbox {.}}}{{Zhao, Yu, Chen, and Zhu}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{9.29999pt}
\newlabel{tocindent2}{11.49998pt}
\newlabel{tocindent3}{20.22pt}
\newlabel{TotPages}{{17}{17}{}{page.17}{}}
